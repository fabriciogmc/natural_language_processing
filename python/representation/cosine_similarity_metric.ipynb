{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "043ebae7-7c6d-4ee4-bdac-25adfd8b0624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vectors corresponding to each sentence: \n",
      "[1. 1. 1. 2. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0.]\n",
      "[0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1.]\n",
      "\n",
      "\n",
      "Similarity cosine matrix: \n",
      "\n",
      "          sent_0    sent_1    sent_2    sent_3    sent_4\n",
      "sent_0  1.000000  0.113961  0.000000  0.369274  0.455842\n",
      "sent_1  0.113961  1.000000  0.503953  0.154303  0.000000\n",
      "sent_2  0.000000  0.503953  1.000000  0.136083  0.125988\n",
      "sent_3  0.369274  0.154303  0.136083  1.000000  0.308607\n",
      "sent_4  0.455842  0.000000  0.125988  0.308607  1.000000\n",
      "\n",
      "\n",
      "Similarity cosine between sentence 1 and sentence 2:  0.5039526306789696\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Basic cosine similarity metric example.\n",
    "\n",
    "In this example, we first build a representation lexicon, and then, \n",
    "for each sentence, we compute the cosine similarity with respect to the others.\n",
    "The current implementation is not efficient but is easy do understand. For\n",
    "real applications replace it by one that uses, for example, a defaultdict data\n",
    "structure.\n",
    "\n",
    "Author: Fabrício Galende M. de Carvalho, DSc\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sentences = [\"gostaria de obter ajuda e essa ajuda é importante\",\n",
    "             \"acho que vai chover e está nublado\",\n",
    "             \"não acho que vai chover hoje pois faz sol\",\n",
    "             \"como será que posso obter ajuda\",\n",
    "             \"não consigo obter ajuda de jeito nenhum\"]\n",
    "\n",
    "def build_representation_lexicon(sentences, representation_lexicon):\n",
    "    for sentence in sentences:\n",
    "        word_tokens = sentence.split() #in real application, replace by preprocessing tokenizer output\n",
    "        for word in word_tokens:\n",
    "            if word not in representation_lexicon:\n",
    "               representation_lexicon.append(word)\n",
    "\n",
    "def build_feature_vector(sentence, representation_lexicon):\n",
    "    feature_vector = np.zeros(len(representation_lexicon))\n",
    "    for pos in range(len(representation_lexicon)):\n",
    "        for word_s in sentence.split():\n",
    "            if word_s == representation_lexicon[pos]:\n",
    "                feature_vector[pos] +=1\n",
    "    return feature_vector\n",
    "\n",
    "representation_lexicon = []\n",
    "build_representation_lexicon(sentences, representation_lexicon)\n",
    "\n",
    "feature_vectors=[]\n",
    "sentence_labels = []\n",
    "for i, sentence in enumerate(sentences):\n",
    "    feature_vectors.append(build_feature_vector(sentence,representation_lexicon))\n",
    "    sentence_labels.append(\"sent_\"+str(i))\n",
    "\n",
    "print(\"Feature vectors corresponding to each sentence: \")\n",
    "for feature_vector in feature_vectors:\n",
    "    print(feature_vector)\n",
    "print(\"\\n\")\n",
    "\n",
    "similarity_matrix = []\n",
    "for x in range(len(feature_vectors)):\n",
    "    similarity_matrix.append([])\n",
    "    for y in range(len(feature_vectors)):\n",
    "        similarity_matrix[x].append( np.dot(feature_vectors[x],\n",
    "                                            feature_vectors[y])/ (np.linalg.norm(feature_vectors[x])*np.linalg.norm(feature_vectors[y]) ))\n",
    "\n",
    "similarity_matrix_df = pd.DataFrame(data=similarity_matrix, index =sentence_labels, columns= sentence_labels)\n",
    "print(\"Similarity cosine matrix: \\n\")\n",
    "print( similarity_matrix_df)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Similarity cosine between sentence 1 and sentence 2: \", similarity_matrix_df.loc[\"sent_1\", \"sent_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd34bae4-d3de-4f4b-a596-139b7614337a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2870f363-196d-4924-a5bb-a09e94f6a6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad9263-33cd-4059-b14a-42baced9f128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "natural_language_processing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
