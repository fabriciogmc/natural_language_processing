{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc6c524e-dc7e-473a-b81b-8187a4b0f29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus representation lexicon:  ['computador' 'do' 'gostei' 'mesmo' 'muito' 'não'] \n",
      "\n",
      "Representation matrix: \n",
      "[[1 1 1 0 1 0]\n",
      " [1 1 1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Count based bag of words using TF-IDF transform.\n",
    "In this example, ContVectorizer and TfidfTransformers\n",
    "classes, from scikit-learn, are used. Logarithms are\n",
    "computed using base e.\n",
    "\n",
    "\n",
    "Author: Fabricio Galende M. de Carvalho, DSc\n",
    "'''\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pandas import DataFrame\n",
    "\n",
    "corpus_documents = [\"Gostei muito do computador\",\n",
    "             \"Não gostei, mesmo, do computador\"]\n",
    "\n",
    "vocabulary = None #['gostei','não','computador']\n",
    "vectorizer = CountVectorizer(vocabulary = vocabulary)\n",
    "document_term_matrix = vectorizer.fit_transform(corpus_documents)\n",
    "corpus_lexicon = vectorizer.get_feature_names_out()\n",
    "print(\"Corpus representation lexicon: \", corpus_lexicon, '\\n')\n",
    "print(\"Representation matrix: \")\n",
    "print(document_term_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2450a6f9-ddcc-44f1-a5ff-f08d299355ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized feature vectors: \n",
      "      computador        do    gostei     mesmo     muito       não\n",
      "doc1    0.448321  0.448321  0.448321  0.000000  0.630099  0.000000\n",
      "doc2    0.379303  0.379303  0.379303  0.533098  0.000000  0.533098\n",
      "\n",
      "\n",
      "Non normalized feature vectors: \n",
      "      computador   do  gostei     mesmo     muito       não\n",
      "doc1         1.0  1.0     1.0  0.000000  1.405465  0.000000\n",
      "doc2         1.0  1.0     1.0  1.405465  0.000000  1.405465\n"
     ]
    }
   ],
   "source": [
    "# Now we perform the TF-IDF transformation with and without array normalization:\n",
    "# In scikit-learn idf(t) = ln [ (1 + n) / (1 + df(t)) ] + 1.\n",
    "# for \"computador\", idf = ln[3/1+2] + 1 = log(1) + 1 = 1\n",
    "# for \"não\", idf = ln[3/2] + 1 = 1.4054\n",
    "\n",
    "tf_idf_transformer_w_normalization = TfidfTransformer(norm = 'l2')\n",
    "tf_idf_transformer_wo_normalization = TfidfTransformer(norm = None)\n",
    "document_term_tfidf_transform_normalized = tf_idf_transformer_w_normalization.fit_transform(document_term_matrix)\n",
    "document_term_tfidf_transform = tf_idf_transformer_wo_normalization.fit_transform(document_term_matrix)\n",
    "\n",
    "\n",
    "document_term_df_norm = DataFrame(data = document_term_tfidf_transform_normalized.toarray(), index = ['doc1', 'doc2'], columns = corpus_lexicon)\n",
    "print(\"Normalized feature vectors: \")\n",
    "print(document_term_df_norm)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Non normalized feature vectors: \")\n",
    "#Lets print in a user-friendly format:\n",
    "document_term_df = DataFrame(data = document_term_tfidf_transform.toarray(), index = ['doc1', 'doc2'], columns = corpus_lexicon)\n",
    "print(document_term_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c371569-0a23-4d07-bae2-c3cfa53041ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      computador        do    gostei     mesmo     muito       não\n",
      "doc1    0.448321  0.448321  0.448321  0.000000  0.630099  0.000000\n",
      "doc2    0.379303  0.379303  0.379303  0.533098  0.000000  0.533098\n"
     ]
    }
   ],
   "source": [
    "# Let's repeat the above representation computation but using TfidfVectorizer.\n",
    "# Note that the result is the same but using a sigle processing step\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df = 0., max_df = 1., norm='l2', use_idf=True)\n",
    "vectorized_docs = tfidf_vectorizer.fit_transform(corpus_documents)\n",
    "document_term_df_b = DataFrame(data = vectorized_docs.toarray(), index = ['doc1', 'doc2'], columns = corpus_lexicon)\n",
    "print(document_term_df_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7aa01b7-f12f-41d7-b8a1-8d4cb0daa25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999\n",
      "2.6364112615862854\n"
     ]
    }
   ],
   "source": [
    "# Let's check the norm for the second sentence using numpy\n",
    "import numpy as np\n",
    "\n",
    "norm_repr_1 = np.linalg.norm(document_term_tfidf_transform_normalized.toarray()[1,:])\n",
    "norm_repr_1b = np.linalg.norm(document_term_tfidf_transform.toarray()[1,:])\n",
    "print(norm_repr_1)\n",
    "print(norm_repr_1b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85d91c3b-5ab2-430c-a79c-fc458c257991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input document representation using count based bow: \n",
      "            input doc\n",
      "computador   0.379303\n",
      "do           0.379303\n",
      "gostei       0.379303\n",
      "mesmo        0.533098\n",
      "muito        0.533098\n",
      "não          0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, let's use the previous model to compute a new feature vector for a new phrase:\n",
    "input_document = [\"gostei, muito mesmo, do computador!\"]\n",
    "input_document_count_vectorized_repr = vectorizer.transform(input_document)\n",
    "input_document_tfidf_repr = tf_idf_transformer_w_normalization.transform(input_document_count_vectorized_repr)\n",
    "input_document_tfidf_repr_dataframe =  DataFrame(data=input_document_tfidf_repr.toarray(), columns = corpus_lexicon, index=[\"input doc\"])\n",
    "print(\"Input document representation using count based bow: \")\n",
    "print(input_document_tfidf_repr_dataframe.transpose())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30deab6f-eb16-404e-bb97-1c61012512ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
