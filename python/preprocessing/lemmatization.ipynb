{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a63bf221-9703-4184-ba32-b08fbeb961c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 21:03:43 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fed6b1aff85427f9dac3c03367ad732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 21:03:44 INFO: Downloaded file to /home/fabriciogmc/stanza_resources/resources.json\n",
      "2025-09-16 21:03:44 INFO: Loading these models for language: pt (Portuguese):\n",
      "==================================\n",
      "| Processor    | Package         |\n",
      "----------------------------------\n",
      "| tokenize     | bosque          |\n",
      "| mwt          | bosque          |\n",
      "| pos          | bosque_charlm   |\n",
      "| lemma        | bosque_nocharlm |\n",
      "| constituency | cintil_charlm   |\n",
      "| depparse     | bosque_charlm   |\n",
      "==================================\n",
      "\n",
      "2025-09-16 21:03:44 INFO: Using device: cpu\n",
      "2025-09-16 21:03:44 INFO: Loading: tokenize\n",
      "2025-09-16 21:03:44 INFO: Loading: mwt\n",
      "2025-09-16 21:03:44 INFO: Loading: pos\n",
      "2025-09-16 21:03:45 INFO: Loading: lemma\n",
      "2025-09-16 21:03:45 INFO: Loading: constituency\n",
      "2025-09-16 21:03:46 INFO: Loading: depparse\n",
      "2025-09-16 21:03:46 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:  Nesse mês ocorreu um fenômeno muito raro durante a primeira semana.\n",
      "Lemmas using spacy:  ['em esse', 'mês', 'ocorrer', 'um', 'fenômeno', 'muito', 'raro', 'durante', 'o', 'primeiro', 'semana', '.']\n",
      "Lemmas using stanza:  ['em', 'esse', 'mês', 'ocorrer', 'um', 'fenômeno', 'muito', 'raro', 'durante', 'o', 'primeiro', 'semana', '.']\n",
      "Original text:   a mulherada correu e viu a lindíssima floreira no vaso da janela rapidamente notou-se que precisaria de água a puríssima e a riquíssima responsável pela vida \n",
      "Lemmas using spacy:  [' ', 'o', 'mulherada', 'correr', 'e', 'ver', 'o', 'lindíssima', 'floreiro', 'em o', 'vaso', 'de o', 'janela', 'rapidamente', 'notour se', 'que', 'precisar', 'de', 'água', 'o', 'puríssima', 'e', 'o', 'riquíssimo', 'responsável', 'por o', 'vida']\n",
      "Lemmas using stanza:  ['o', 'mulherada', 'correr', 'e', 'ver', 'o', 'lindíssimo', 'floreira', 'em', 'o', 'vaso', 'de', 'o', 'janela', 'rapidamente', 'notar', 'se', 'que', 'precisar', 'de', 'água', 'a', 'purossimo', 'e', 'o', 'riquíssimo', 'responsável', 'por', 'o', 'vida']\n"
     ]
    }
   ],
   "source": [
    "# This examples illustrates a simple word lemmatization\n",
    "# using stanza library and also spacy library\n",
    "#\n",
    "# Author: Fabrício Galende Marques de Carvalho\n",
    "\n",
    "\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "import stanza\n",
    "\n",
    "\n",
    "\n",
    "# stanza.download('pt')\n",
    "stanza_nlp = stanza.Pipeline('pt')\n",
    "\n",
    "\n",
    "sample_text_pt_1 = \"Nesse mês ocorreu um fenômeno muito raro durante a primeira semana.\"\n",
    "sample_text_pt_2 = (\" a mulherada correu e viu a lindíssima floreira no vaso da janela\" \n",
    "                     \" rapidamente notou-se que precisaria de água\" \n",
    "                     \" a puríssima e a riquíssima responsável pela vida \")\n",
    "\n",
    "spacy_nlp = spacy.load('pt_core_news_sm',  disable = ['parser','ner'])\n",
    "print(\"Original text: \", sample_text_pt_1)\n",
    "print(\"Lemmas using spacy: \", [ token.lemma_ for token in spacy_nlp(sample_text_pt)])\n",
    "print(\"Lemmas using stanza: \", [ word.lemma for sentence in stanza_nlp(sample_text_pt).sentences for word in sentence.words])\n",
    "\n",
    "print(\"Original text: \", sample_text_pt_2)\n",
    "print(\"Lemmas using spacy: \", [ token.lemma_ for token in spacy_nlp(sample_text_pt_2)])\n",
    "print(\"Lemmas using stanza: \", [ word.lemma for sentence in stanza_nlp(sample_text_pt_2).sentences for word in sentence.words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57868114-9906-42ec-b02d-7737c25ddac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "natural_language_processing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
